{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe0672b-38af-4dae-aa7d-d638cb1b1c08",
   "metadata": {},
   "source": [
    "# Escenario 1.1. - Alice y Bob sin clave\n",
    "\n",
    "En este escenario se cubre el caso en el que Alice cifra para Bob y Bob descifra los mensajes sin utilizar ninguna clave.\n",
    "\n",
    "Se lleva a cabo un entrenamiento, una evaluación de los resultados y se dibuja una gráfica para ilustrarlos. Como se hacen muchas ejecuciones, se grafica el resultado obtenido en cada ejecución. Hay cierta variabilidad en los resultados al ser los pesos de las redes neuronales aleatorios, así como los mensajes generados en el entrenamiento y la evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f66bf-6c49-4885-8038-1e77b7c44dca",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a91d05c-b5c4-4d70-82dd-b2351632e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "from data_utils import generar_mensajes\n",
    "\n",
    "import numpy as np\n",
    "import time as t\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e7b67-9064-4c3b-b768-6a14a5fb1a69",
   "metadata": {},
   "source": [
    "## Las redes neuronales\n",
    "\n",
    "En esta sección definimos las redes a utilizar más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d6d83-c870-4c6b-93b4-2c652a19b3a7",
   "metadata": {},
   "source": [
    "**Alice**: Red neuronal que cifra los mensajes.\n",
    "1. Recibe como parámetro el número de bits de los mensajes que va a cifrar y entonces define la forma de entrada.\n",
    "2. Se le asigna tanto a x, para manipular los datos desde la entrada, como a final_input, ya que va a tener la misma forma.\n",
    "3. Va a tener dos capas, con 128 y 64 neuronas, que reciben la entrada de la anterior y usan la función de activación relu. _Dense_ quiere decir que la capa está completamente conectada con la anterior.\n",
    "\n",
    "La última capa tiene una función de activación lineal porque luego la va a procesar Bob. No es necesario que sea binaria todavía. Tiene también tantas neuronas como bits, porque se busca que saque el mensaje cifrado y, por último, la función kernel_regularizer ayuda a evitar el sobreajuste penalizando las capas, de forma a que afecta la función de pérdida/coste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fedee013-7edd-4563-bce5-a3c4165b70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo_alice(bits):\n",
    "    input_msg = Input(shape=(bits,), name='mensaje_original')\n",
    "    \n",
    "    x = input_msg\n",
    "    final_input = input_msg\n",
    "\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "\n",
    "    cifrado = Dense(bits, activation='linear', kernel_regularizer=l2(0.01))(x)\n",
    "    return Model(final_input, cifrado, name='Alice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb152bc-8398-48c2-8408-02c0295c19ba",
   "metadata": {},
   "source": [
    "**Bob**: Red neuronal que descifra los mensajes.\n",
    "Funciona parecido a Alice, salvo que tiene capas de 64 y 64 neuronas. \n",
    "Lo más destacable es que la función de activación de la última capa es, en este caso, la función sigmoide. La función sigmoide devuelve un valor entre 0 y 1 y esos son los valores que luego se procesan para inferir si la predicción es el valor 0 o el valor 1 en la reconstrucción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a691d9fc-f129-4d3f-8342-d33fa27eae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo_bob(bits):\n",
    "    input_cifrado = Input(shape=(bits,), name='mensaje_cifrado')\n",
    "\n",
    "    x = input_cifrado\n",
    "    final_input = input_cifrado\n",
    "    \n",
    "    \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "\n",
    "    reconstruido = Dense(bits, activation='sigmoid')(x)\n",
    "    return Model(final_input, reconstruido, name='Bob')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751665ed-3492-4128-a228-6ac94be0ccf5",
   "metadata": {},
   "source": [
    "## Código de entrenamiento\n",
    "\n",
    "Esta sección se encarga de entrenar los modelos de Alice y Bob. Tiene tres métodos:\n",
    "* El método crear_modelo_conjunto, que crea el modelo a entrenar de forma conjunta. El por qué se verá en el escenario 1.3.\n",
    "* El método entrenar_modelo, que entrena ese modelo conjunto.\n",
    "* El método principal entrenar, que utiliza los método anteriores para instanciar las redes neuronales, entrenarlas y guardar los modelos, lo cuál es vital para luego poder utilizarlos en la evaluación.\n",
    "\n",
    "Nótese que se recoge la duración del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf62561-3984-409a-8957-3631d13b5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo_conjunto(bits):\n",
    "    alice = crear_modelo_alice(bits)\n",
    "    bob = crear_modelo_bob(bits)\n",
    "\n",
    "    # Modelo combinado sin clave\n",
    "    modelo = Model(alice.input, bob(alice.output))\n",
    "\n",
    "    return alice, bob, modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f4d777-ab53-4846-8de7-236e1a1b142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo(modelo, n_mensajes, epochs, mensajes, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        # Se selecciona un lote aleatorio de mensajes, que es lo que va en mensajes_batch para evitar overfitting\n",
    "        idx = np.random.choice(n_mensajes, batch_size)\n",
    "        mensajes_batch = mensajes[idx]\n",
    "\n",
    "        # Entrenamiento sin clave\n",
    "        modelo.train_on_batch(mensajes_batch, mensajes_batch)\n",
    "        reconstruidos = modelo.predict(mensajes_batch)\n",
    "        \n",
    "        # Media de todos los reonstruidos correctamente\n",
    "        precision = np.mean((reconstruidos > 0.5).astype(int) == mensajes_batch)\n",
    "        print(f\" Epochs totales: {epochs}| Epoch {epoch+1} - Precisión del descifrado: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aacbd1f-4471-4ea7-94ce-4f17d7aedb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(n_mensajes, bits, epochs, batch_size, adam_optimizer):\n",
    "    # Generamos los mensajes\n",
    "    mensajes = generar_mensajes(n_mensajes, bits)\n",
    "\n",
    "    # Instanciamos los modelos y obtenemos el combinado\n",
    "    alice, bob, modelo = crear_modelo_conjunto(bits)\n",
    "\n",
    "    # Se prepara el modelo para entrenarlo con Adam y BinaryCrossEntropy\n",
    "    modelo.compile(optimizer=Adam(adam_optimizer), loss=BinaryCrossentropy())\n",
    "    \n",
    "    time_0 = t.time()\n",
    "    \n",
    "    # Comienza el entrenamiento\n",
    "    entrenar_modelo(modelo, n_mensajes, epochs, mensajes, batch_size)\n",
    "\n",
    "    time = t.time() - time_0\n",
    "\n",
    "    # Guardamos los modelos entrenados para luego usarlos en la evaluación\n",
    "    alice.save('modelo_alice.keras')\n",
    "    bob.save('modelo_bob.keras')\n",
    "\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3184a76-cb42-469a-8603-f9da3c7327e4",
   "metadata": {},
   "source": [
    "## Código de evaluación\n",
    "\n",
    "Esta sección se encarga de evaluar el entrenamiento y consiste también en tres métodos:\n",
    "* El método cargar_modelos, que crea a Alice y a Bob y les carga los pesos finales obtenidos en el entrenamiento.\n",
    "* El método analizar_resultados, que recoge una serie de métricas: la precisión media, la distancia de Hamming media y el número de reconstrucciones perfectas obtenido.\n",
    "* El método evaluar, que usa los anteriores para llevar a cabo la evaluación. Este método devuelve las métricas que luego se enviarán al método que dibuja las gráficas.\n",
    "\n",
    "Nótese que también se incluye el escribir en un fichero de texto los resultados. Así se pueden consultar los resultados exactos más fácilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8b00ea-2b56-4fe7-905c-84a31d5b4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelos(bits):\n",
    "    alice = crear_modelo_alice(bits)\n",
    "    bob = crear_modelo_bob(bits)\n",
    "\n",
    "    alice.load_weights('modelo_alice.keras')\n",
    "    bob.load_weights('modelo_bob.keras')\n",
    "\n",
    "    return alice, bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c96d2fc1-6cc7-4df5-a94b-e64c7096a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_resultados(muestras, res_file_name, mensajes, reconstruidos):\n",
    "    \n",
    "    precisiones = []\n",
    "    distancias = []\n",
    "    reconstrucciones_perfectas = 0\n",
    "    \n",
    "    for i in range(len(reconstruidos)):\n",
    "        \n",
    "        original = mensajes[i].astype(int)\n",
    "        reconstruido = (reconstruidos[i] > 0.5).astype(int)\n",
    "        \n",
    "        # Coges el original y el reconstruido y haces la media de cuántos bits se parecen\n",
    "        precision = np.mean(original == reconstruido)\n",
    "        distancia_hamming = np.sum(original != reconstruido)\n",
    "\n",
    "        if i < muestras:\n",
    "\n",
    "            str_mensaje_original = f\"Original     --> {original}\\n\"\n",
    "            str_precision_reconstruido = f\"Reconstruido --> {reconstruido} | Precisión: {precision:.2f}\\n\"\n",
    "            str_distancia_hamming = f\"Distancia de Hamming: {distancia_hamming}\\n\"\n",
    "            str_mensaje_delimiter = (\"-\" * 50) + \"\\n\"\n",
    "            str_muestra = str_mensaje_original + str_precision_reconstruido + str_distancia_hamming + str_mensaje_delimiter\n",
    "            with open(res_file_name, \"a\") as f:\n",
    "                f.write(str_muestra)\n",
    "\n",
    "\n",
    "        precisiones.append(precision)\n",
    "        distancias.append(distancia_hamming)\n",
    "        if distancia_hamming == 0:\n",
    "            reconstrucciones_perfectas += 1\n",
    "    \n",
    "    return precisiones, distancias, reconstrucciones_perfectas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf73ec6-7fbd-44f0-8620-f7623a00eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar(n_mensajes, bits, muestras, res_file_name, epochs):\n",
    "    \n",
    "    # Cargamos los modelos y los pesos del entrenamiento anterior\n",
    "    alice, bob = cargar_modelos(bits)\n",
    "\n",
    "    # Generamos los mensajes\n",
    "    mensajes = generar_mensajes(n_mensajes, bits)\n",
    "    \n",
    "    # Se cifran y descifran los mensajes\n",
    "    cifrados = alice.predict(mensajes)\n",
    "    reconstruidos = bob.predict(cifrados)\n",
    "\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(f\"\\nEVALUACIÓN CON {epochs}:\\n\\n\")\n",
    "\n",
    "    precisiones, distancias, reconstrucciones_perfectas = analizar_resultados(muestras, res_file_name, mensajes, reconstruidos)\n",
    "    \n",
    "    media_precision = np.mean(precisiones)\n",
    "    media_distancias = np.mean(distancias)\n",
    "    \n",
    "    str_media_precision = f\"La media de la precisión del descifrado es {media_precision:.4f}\\n\"\n",
    "    str_media_distancias = f\"Distancia media de Hamming = {media_distancias:.4f} | Número de bits: {bits}\\n\"\n",
    "    str_reconstrucciones_perfectas = f\"Número de reconstrucciones perfectas = {reconstrucciones_perfectas}\\n\"\n",
    "    str_medidas = str_media_precision + str_media_distancias + str_reconstrucciones_perfectas +\"\\n\\n\"\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(str_medidas)\n",
    "\n",
    "    return [media_precision, media_distancias, reconstrucciones_perfectas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8df37-5d8b-471c-bd9c-1d26754355de",
   "metadata": {},
   "source": [
    "## Representando los resultados\n",
    "\n",
    "Tan importante como desarrollar un buen código, es poder enseñar los resultados de manera ilustrativa. Para ello, en esta sección se define la creación de una gráfica para poder visualizar los resultados obtenidos en la ejecución. Las métricas se recogen en el main y se guardan en un diccionario. Así mismo, también recibe el nombre de la figura, al que simplemente se le añade el formato al guardarla y el número de mensajes, que es útil para establecer un límite en la gráfica que muestra las reconstrucciones perfectas realizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c8da03-1365-4ea4-a826-2726ede271c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(diccionario_medidas, n_mensajes, nombre_figura):\n",
    "\n",
    "    list_epochs = diccionario_medidas[\"epochs\"]\n",
    "    list_training_times = diccionario_medidas[\"training_times\"]\n",
    "    list_media_precision = diccionario_medidas[\"media_precision\"]\n",
    "    list_media_distancias = diccionario_medidas[\"media_distancias\"]\n",
    "    list_reconstrucciones_perfectas = diccionario_medidas[\"reconstrucciones_perfectas\"]\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(list_epochs, list_training_times, c=\"red\", marker='o', markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Duración entrenamiento (s)\")\n",
    "    plt.title(\"Entrenamiento - Epochs\")\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(bottom = 0)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(list_epochs, list_media_precision, c=\"red\", marker='o', markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Media precisión descifrado\")\n",
    "    plt.title(\"Precisión media - Epochs\")\n",
    "    plt.xlim(left = 0)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(list_epochs, list_media_distancias, c=\"red\", marker='o', markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Media distancias de Hamming\")\n",
    "    plt.title(\"Distancias de Hamming - Epochs\")\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(bottom = 0)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(list_epochs, list_reconstrucciones_perfectas, c=\"red\", marker='o', markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Reconstrucciones perfectas\")\n",
    "    plt.title(\"Reconstrucciones perfectas - Epochs\")\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(0, n_mensajes)\n",
    "\n",
    "    plt.subplots_adjust(left = 0.125, bottom = 0.11, right = 1.1, top = 0.9, wspace = 0.44, hspace = 0.45)\n",
    "    plt.savefig(nombre_figura + \".png\", bbox_inches='tight', dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1f1545-c0c7-4120-b1c0-7144c7af8abd",
   "metadata": {},
   "source": [
    "## Código principal\n",
    "\n",
    "Aquí se define el código principal. Este es un main que tiene un bucle que ejecuta el código una vez. Con ayuda de bucles se puede conseguir que se ejecute más veces, y es lo que se hizo para obtener los resultados más cómodamente, pero en este caso, en pro de visualizar la gráfica resultante, se ha dejado una sola  ejecución.\n",
    "\n",
    "Aquí es donde se definen los hiperparámetros que se utilizarán, como el tamaño del _batch_.\n",
    "\n",
    "La ejecución tarda en completarse, puede llegar a una hora. Por ello, se han dejado los mensajes que Tensorflow y Keras imprimen por pantalla y se ha añadido uno, que sale en cada ronda de entrenamiento y da información acerca de por dónde y cómo va. Hay mucha salida, pero el tamaño queda limitado.\n",
    "\n",
    "Además, aquí se recogen las métricas que se usan para dibujar las gráficas, los métodos de entrenamiento y evaluación devuelven el tiempo que duró el entrenamiento y las métricas recogidas durante la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454e870-38c9-43bd-89e5-0a95cfb9451e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    n_mensajes = 10000\n",
    "    bits = 32\n",
    "    batch_size = 512\n",
    "    adam_optimizer = 0.001\n",
    "    muestras = 10\n",
    "    \n",
    "    epochs = 300\n",
    "    step = 300\n",
    "    total_epochs = 6000\n",
    "\n",
    "    res_file_name = f\"Resultados_11_{batch_size}_{adam_optimizer}.txt\"\n",
    "    nombre_figura = f\"Figura 11 - {batch_size} y {adam_optimizer}\"\n",
    "    with open(res_file_name, \"w\") as f:\n",
    "        f.write(\"-- RESULTADOS DEL EXPERIMENTO 1.1. --\\n\\n\")\n",
    "            \n",
    "\n",
    "        diccionario_medidas = {\n",
    "            \"epochs\": [],\n",
    "            \"training_times\": [],\n",
    "            \"media_precision\": [],\n",
    "            \"media_distancias\": [],\n",
    "            \"reconstrucciones_perfectas\": []\n",
    "        }\n",
    "\n",
    "        with open(res_file_name, \"a\") as f:\n",
    "            f.write(f\"Número de mensajes = {n_mensajes}\\n\")\n",
    "            f.write(f\"Número de bits = {bits}\\n\")\n",
    "            f.write(f\"Tamaño del batch = {batch_size}\\n\")\n",
    "            f.write(f\"Adam optimizer learning rate = {adam_optimizer}\\n\")\n",
    "            f.write(f\"Epochs totales = {total_epochs}\\n\")\n",
    "            f.write(f\"Epochs iniciales = {epochs}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        tiempo_inicial = t.time()\n",
    "        while epochs <= total_epochs:\n",
    "            \n",
    "            training_time = entrenar(n_mensajes, bits, epochs, batch_size, adam_optimizer)\n",
    "            res_list = evaluar(n_mensajes, bits, muestras, res_file_name, epochs)\n",
    "\n",
    "            media_precision = res_list[0]\n",
    "            media_distancias = res_list[1]\n",
    "            reconstrucciones_perfectas = res_list[2]\n",
    "\n",
    "            diccionario_medidas[\"epochs\"].append(epochs)\n",
    "            diccionario_medidas[\"training_times\"].append(training_time)\n",
    "            diccionario_medidas[\"media_precision\"].append(media_precision)\n",
    "            diccionario_medidas[\"media_distancias\"].append(media_distancias)\n",
    "            diccionario_medidas[\"reconstrucciones_perfectas\"].append(reconstrucciones_perfectas)\n",
    "\n",
    "            epochs += step\n",
    "\n",
    "        tiempo_total = t.time() - tiempo_inicial\n",
    "        with open(res_file_name, \"a\") as f:\n",
    "            f.write(f\"Tiempo total de ejecución (s): {tiempo_total}\\n\\n\")\n",
    "        \n",
    "        draw_graph(diccionario_medidas, n_mensajes, nombre_figura)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b9516-c623-4006-a09e-059486d0fa37",
   "metadata": {},
   "source": [
    "El resultado de la ejecución aparecerá encima de este texto y producirá una imagen al finalizar la ejecución con todos los resultados. Además, la imagen generada con las gráficas también queda guardada en el directorio de esta Jupyter Notebook.\n",
    "\n",
    "Se anima a jugar con los parámetros, como el tamaño del _batch_, las _epochs_, el _adam optimizer_... para probar el rendimiento en distintos casos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
