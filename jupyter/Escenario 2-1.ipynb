{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9795f92d-05bb-4f0e-8f97-89ca5f35aeb7",
   "metadata": {},
   "source": [
    "# Escenario 2.1 - Alice y Bob con clave vs Eve\n",
    "\n",
    "En este escenario se cubre el caso en el que Alice cifra para Bob y Bob descifra los mensajes por medio de una clave. Sin embargo, se ha añadido un agente malicioso, Eve, que quiere interceptar la comunicación.\n",
    "\n",
    "Se lleva a cabo un entrenamiento, una evaluación de los resultados y se dibuja una gráfica para ilustrarlos. Como se hacen muchas ejecuciones, se grafica el resultado obtenido en cada ejecución. Hay cierta variabilidad en los resultados al ser los pesos de las redes neuronales aleatorios, así como los mensajes generados en el entrenamiento y la evaluación.\n",
    "\n",
    "Avisar del tiempo, una ejecución con las _epochs_ definidas por defecto (de 300 en 300 hasta llegar a 6000), puede tardar el triple que en los escenarios 1 debido al aumento en la complejidad del escenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fbf194-b458-4c22-ac28-968ee188be4e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d52ed6f-1fa1-4fde-98f4-21a8b34849d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "from data_utils import generar_mensajes\n",
    "\n",
    "import numpy as np\n",
    "import time as t\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e658e3-28df-467c-8ba2-1ce147540387",
   "metadata": {},
   "source": [
    "## Las redes neuronales\n",
    "\n",
    "En esta sección definimos las redes a utilizar más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919880c0-465e-4c6e-a8f4-1fdd0e132606",
   "metadata": {},
   "source": [
    "**Alice**: Red neuronal que cifra los mensajes.\n",
    "1. Recibe como parámetro el número de bits de los mensajes que va a cifrar y entonces define la forma de entrada.\n",
    "2. Concatena el mensaje de entrada con al clave y eso es lo que se le pasa a la red, para cifrar así el mensaje.\n",
    "3. final_input va a recibir algo de la forma mensaje + clave, por lo que esta vez recibe una dupla.\n",
    "4. Va a tener dos capas, con 128 y 64 neuronas, que reciben la entrada de la anterior y usan la función de activación relu. _Dense_ quiere decir que la capa está completamente conectada con la anterior.\n",
    "\n",
    "La última capa tiene una función de activación lineal porque luego la va a procesar Bob. No es necesario que sea binaria todavía. Tiene también tantas neuronas como bits, porque se busca que saque el mensaje cifrado y, por último, la función kernel_regularizer ayuda a evitar el sobreajuste penalizando las capas, de forma a que afecta la función de pérdida/coste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0259315b-8ff0-41fe-bd66-cfbabb836384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo_alice(bits):\n",
    "    input_msg = Input(shape=(bits,), name='mensaje_original')\n",
    "\n",
    "    input_key = Input(shape=(bits,), name='clave_simetrica')\n",
    "    x = Concatenate()([input_msg, input_key])\n",
    "    final_input = [input_msg, input_key]\n",
    "\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    cifrado = Dense(bits, activation='linear', kernel_regularizer=l2(0.01))(x)\n",
    "    return Model(final_input, cifrado, name='Alice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a40d6-ba17-4a7e-af6d-28d8660c3ead",
   "metadata": {},
   "source": [
    "**Bob**: Red neuronal que descifra los mensajes.\n",
    "Funciona parecido a Alice, salvo que tiene capas de 64 y 64 neuronas. \n",
    "Lo más destacable es que la función de activación de la última capa es, en este caso, la función sigmoide. La función sigmoide devuelve un valor entre 0 y 1 y esos son los valores que luego se procesan para inferir si la predicción es el valor 0 o el valor 1 en la reconstrucción.\n",
    "\n",
    "Como siempre, el mensaje cifrado y la clave se concatenan para llevar a cabo el descifrado.\n",
    "\n",
    "En este caso, cabe mencionar que, para evitar sobreajuste, se ha añadido un _dropout_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa29562a-056d-4dbc-9757-048f1987e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo_bob(bits):\n",
    "    input_cifrado = Input(shape=(bits,), name='mensaje_cifrado')\n",
    "    input_key = Input(shape=(bits,), name='clave_simetrica')\n",
    "    x = Concatenate()([input_cifrado, input_key])\n",
    "    final_input = [input_cifrado, input_key]\n",
    "    \n",
    "    \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    reconstruido = Dense(bits, activation='sigmoid')(x)\n",
    "    return Model(final_input, reconstruido, name='Bob')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b270b14-7b4d-4943-8855-b73f7817f2da",
   "metadata": {},
   "source": [
    "**Eve**: Red neuronal que pretende interceptar los mensajes.\n",
    "Funciona como Bob, salvo que no recibe niguna clave, solo el mensaje cifrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1137f5c5-b072-40a3-b0b4-c6189427cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo_eve(bits):\n",
    "    input_cifrado = Input(shape=(bits,), name=f'mensaje_cifrado_eve')\n",
    "    x = Dense(64, activation='relu')(input_cifrado)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    salida = Dense(bits, activation='sigmoid', name=f'mensaje_reconstruido_eve')(x)\n",
    "    return Model (input_cifrado, salida, name='Eve')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a43db5a-df1f-461e-a8e9-be3cd5d65d3b",
   "metadata": {},
   "source": [
    "## Código de entrenamiento\n",
    "\n",
    "Esta sección se encarga de entrenar los modelos de Alice, Bob e Eve utilizando un enfoque adversarial. Tiene una mayor complejidad que el entrenamiento de los casos 1.1., 1.2. y 1.3., al tener un agente más. Hay seis métodos:\n",
    "\n",
    "* generar_claves_y_mensajes(n_mensajes, bits)\n",
    "* crear_modelos(bits)\n",
    "* generar_batch(n_mensajes, batch_size, mensajes, claves)\n",
    "* actualizar_mejor_loss(alice, bob, eve, loss_total, epoch)\n",
    "* toma_de_medidas(mensajes_batch, cifrado_batch, claves_batch, claves_dummy, bob, eve)\n",
    "* entrenar(n_mensajes, bits, epochs, batch_size, adam_optimizer_rate, alfa, beta, gamma)\n",
    "\n",
    "Nótese que se recoge la duración del entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff80eaf-7b57-49a2-99d1-13cf20bbfd36",
   "metadata": {},
   "source": [
    "**generar_claves_y_mensajes**: Este método genera los mensaje sy claves aleatorios que se utilizarán durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "24fb8942-8910-4afb-9d04-3b08d7728ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_claves_y_mensajes(n_mensajes, bits):\n",
    "    # Generando mensajes\n",
    "    mensajes = generar_mensajes(n_mensajes, bits)\n",
    "\n",
    "    # Generando claves\n",
    "    claves = np.random.randint(0, 2, (n_mensajes, bits)).astype(np.float32)\n",
    "\n",
    "    return mensajes, claves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d618135-1f79-4d08-8e93-6ef2d08807ea",
   "metadata": {},
   "source": [
    "**crear_modelos**: Este método crea las redes neuronales utilziando los métodoa anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73e7480f-f7db-449c-965a-be01a6d589df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelos(bits):\n",
    "    alice = crear_modelo_alice(bits)\n",
    "    bob = crear_modelo_bob(bits)\n",
    "    eve = crear_modelo_eve(bits)\n",
    "\n",
    "    return alice, bob, eve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc92f0-4470-4492-bb18-59e2b3608b7a",
   "metadata": {},
   "source": [
    "**generar_batch**: Genera los mensajes y claves del _batch_ actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb1f3e47-eac2-4436-aa15-85479f3e1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_batch(n_mensajes, batch_size, mensajes, claves):\n",
    "    idx = np.random.permutation(n_mensajes)[:batch_size]\n",
    "    mensajes_batch = mensajes[idx]\n",
    "    claves_batch = claves[idx]\n",
    "\n",
    "    return mensajes_batch, claves_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e608ac-209d-448a-bf2b-4420ab7c7ddf",
   "metadata": {},
   "source": [
    "**actualizar_mejor_loss**: Actualiza el valor de la función de pérdida y guarda los modelos si el valor de esta ha mejorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff3fe9a0-6713-488c-b9b0-9c6fbc5581a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_mejor_loss(alice, bob, eve, loss_total, epoch):\n",
    "    mejor_loss = loss_total\n",
    "    alice.save('modelo_alice.keras')\n",
    "    bob.save('modelo_bob.keras')\n",
    "    eve.save('modelo_eve.keras')\n",
    "    print(f\"Modelos guardados en epoch {epoch+1} (loss_total={loss_total:.4f})\")\n",
    "    \n",
    "    return mejor_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2463a12f-ee7b-44be-bd75-1b4966760efc",
   "metadata": {},
   "source": [
    "**toma_de_medidas**_ Mide las precisiones para poder ir viendo cómo evolucionan por consola con el pasar de las _epochs_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24d43a50-48e0-4c67-b87f-4f485d3243c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toma_de_medidas(mensajes_batch, cifrado_batch, claves_batch, claves_dummy, bob, eve):\n",
    "\n",
    "    prediccion_bob = (bob.predict([cifrado_batch, claves_batch]) > 0.5).astype(int)\n",
    "    prediccion_errores = (bob.predict([cifrado_batch, claves_dummy]) > 0.5).astype(int)\n",
    "\n",
    "    precision_bob = np.mean(prediccion_bob  == mensajes_batch)\n",
    "    precision_errores = np.mean(prediccion_errores == mensajes_batch)\n",
    "    precision_eve = np.mean((eve.predict(cifrado_batch) > 0.5).astype(int) == mensajes_batch)\n",
    "\n",
    "    return precision_bob, precision_errores, precision_eve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3d0f99-3b1d-4975-bd0c-3650fad020c2",
   "metadata": {},
   "source": [
    "**entrenar**: El método principal del entrenamiento.\n",
    "\n",
    "1. Se crean Alice, Bob e Eve\n",
    "2. Ya se compila el modelo de Eve\n",
    "3. Se definen las entradas entradas y las redes que quedan\n",
    "4. Se instancia Eve con los mensajes cifrados y se pone su campo _trainable_ a falso. Esto es porque se va aentrenar de forma alternada con Alice y Bob.\n",
    "5. Se crea y se compila un modelo conjunto con los dos Bob y con Eve.\n",
    "6. Entonces comienza el entrenamiento.\n",
    "\n",
    "La particularidad que tiene este entrenamiento es que primero se entrena Eve y luego a Alice y Bob, de manera alternada. De esaa forma, Eve intenta aprender a descifrar bien y Alice y Bob cuando les toca la penalizan para evitarlo. Debido a que las funciones de coste/pérdida son sumas, se ha definido que el objetivo a conseguir por Eve cuando está con Alice y Bob sea descifrar mal, para darle esa penalziación. Por ello, en la función se suma el valor de que Eve descifre los mensajes de manera invertida.\n",
    "\n",
    "Después de esto se toman las medidas y se muestran por pantalla, así como la _epoch_ actuual y las _epochs_ _totales_ actuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d4d1add-ce99-46fc-83bc-d66b165c9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(n_mensajes, bits, epochs, batch_size, adam_optimizer_rate, alfa, beta, gamma):\n",
    "    \n",
    "    mensajes, claves = generar_claves_y_mensajes(n_mensajes, bits)\n",
    "\n",
    "    # Creando los modelos\n",
    "    alice, bob, eve = crear_modelos(bits)\n",
    "\n",
    "    # Compilamos a Eve (solo una loss)\n",
    "    eve.compile(optimizer=Adam(adam_optimizer_rate), loss='binary_crossentropy')\n",
    "   \n",
    "    mensajes_input = alice.input[0]\n",
    "    claves_input = alice.input[1]\n",
    "    claves_erroneas = Input(shape=(bits,), name='clave_err') \n",
    "\n",
    "    # Construimos Alice, Bob e Eve con las entradas correspondientes\n",
    "    # Nótese que hay 2 Bobs, para segurarnos de que Bob descifra con claves correctas\n",
    "    cifrado = alice([mensajes_input, claves_input])\n",
    "    bob_bien = bob([cifrado, claves_input])\n",
    "    bob_err = bob([cifrado, claves_erroneas])\n",
    "\n",
    "    # Vital para entrenamiento adversarial\n",
    "    eve.trainable = False\n",
    "    eve_adv = eve(cifrado)\n",
    "\n",
    "    # Creamos y compilamos el modelo conjunto\n",
    "    # Creamos el modelo conjunto\n",
    "    model_ab = Model(\n",
    "        inputs  = [mensajes_input, claves_input, claves_erroneas],\n",
    "        outputs = [bob_bien, bob_err, eve_adv]\n",
    "    )\n",
    "    \n",
    "    # Se especifican tres funciones de pérdida diferentes\n",
    "    model_ab.compile(\n",
    "        optimizer    = Adam(adam_optimizer_rate),\n",
    "        loss         = ['binary_crossentropy','binary_crossentropy','binary_crossentropy'],\n",
    "        loss_weights = [gamma, beta, alfa]\n",
    "    )\n",
    "\n",
    "    mejor_loss = float('inf')\n",
    "\n",
    "    time_0 = t.time()\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "        \n",
    "        # Generamos los mensajes y las claves de este batch\n",
    "        mensajes_batch, claves_batch = generar_batch(n_mensajes, batch_size, mensajes, claves)\n",
    "\n",
    "        # Generamos los mensajes cifrados ya entrenamos a Eve\n",
    "        cifrado_batch = alice.predict([mensajes_batch, claves_batch])\n",
    "        loss_eve = eve.train_on_batch(cifrado_batch, mensajes_batch)\n",
    "\n",
    "        # Generamos claves dummy y lo que hay que estimar a partir de ellas.\n",
    "        # Coon esto enseñaremos a Bob a cifrar mal si no tiene la clave correcta\n",
    "        claves_dummy = np.random.randint(0,2,(batch_size,bits)).astype(np.float32)\n",
    "        y_estimada = np.zeros_like(mensajes_batch)\n",
    "\n",
    "        y_eve_invertida = 1. - mensajes_batch\n",
    "\n",
    "        resultados = model_ab.train_on_batch(\n",
    "            [mensajes_batch, claves_batch, claves_dummy],\n",
    "            [mensajes_batch, y_estimada, y_eve_invertida]\n",
    "        )\n",
    "        # Recuperamos las losses\n",
    "        loss_total, loss_bob, loss_bob_errores, loss_eve_invertida = resultados\n",
    "        # Ese loss_total es gamma * loss_bob + beta * loss_bob_errores + alfa * loss_eve_invertida\n",
    "        # Por ese + alfa * loss_eve_invertida es que lo invertimos, para penalizar a Eve\n",
    "        \n",
    "        # Actualizamos la pérdida, y los modelos, si esta ha mejorado\n",
    "        if loss_total < mejor_loss:\n",
    "            mejor_loss = actualizar_mejor_loss(alice, bob, eve, loss_total, epoch)\n",
    "\n",
    "        # Métricas de precisión que se imprimen por epoch\n",
    "        precision_bob, precision_errores, precision_eve = toma_de_medidas(mensajes_batch, cifrado_batch, claves_batch, claves_dummy, bob, eve)\n",
    "\n",
    "        # Mostramos el avance de las medidas por epochs\n",
    "        print(\n",
    "            f\"EPOCHS TOTALES = {epochs} |\"\n",
    "            f\"[Epoch {epoch+1:03}] | \"\n",
    "            f\"Bob_ok={precision_bob:.3f} | \"\n",
    "            f\"Bob_err={precision_errores:.3f} | \"\n",
    "            f\"Eve_acc={precision_eve:.3f} | \"\n",
    "            f\"loss_bob={loss_bob:.4f} | \"\n",
    "            f\"loss_bob_errores={loss_bob_errores:.4f} | \"\n",
    "            f\"loss_eve={loss_eve:.4f} | \"\n",
    "            f\"loss_eve_inv={loss_eve_invertida:.4f}\"\n",
    "        )\n",
    "    time = t.time() - time_0\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20591516-620f-493b-9d06-e526b3725c5a",
   "metadata": {},
   "source": [
    "## Código de evaluación\n",
    "\n",
    "Esta sección se encarga de evaluar el entrenamiento y consiste en lo siguiente:\n",
    "* crear_y_cargar_modelos(bits)\n",
    "* generar_mensajes_y_claves(n_mensajes, bits)\n",
    "* analizar_resultados(mensajes, cifrados, reconstruidos_bob, reconstruidos_eve, muestras, res_file_name)\n",
    "* analizar_resultados_errado(bob, bits, mensajes, cifrados, muestras, res_file_name)\n",
    "* evaluar(n_mensajes, bits, muestras, epochs, res_file_name)\n",
    "\n",
    "Nótese que también se incluye el escribir en un fichero de texto los resultados. Así se pueden consultar los resultados exactos más fácilmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e7371-e805-4d99-9d90-6c78190bf36f",
   "metadata": {},
   "source": [
    "**crear_y_cargar_modelos**: Crea a Alice, Bob e Eve y les carga los pesos finales obtenidos en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33918e71-8c4e-45a6-abf3-b7b4b9d1d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_y_cargar_modelos(bits):\n",
    "    # Se instancian los modelos\n",
    "    alice = crear_modelo_alice(bits)\n",
    "    bob = crear_modelo_bob(bits)\n",
    "    eve = crear_modelo_eve(bits)\n",
    "\n",
    "    # Se cargan los pesos del entrenamiento anterior\n",
    "    alice.load_weights('modelo_alice.keras')\n",
    "    bob.load_weights('modelo_bob.keras')\n",
    "    eve.load_weights('modelo_eve.keras')\n",
    "\n",
    "    return alice, bob, eve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf398a-3821-4e03-980e-8112f9884249",
   "metadata": {},
   "source": [
    "**generar_mensajes_y_claves**: Genera las claves y mensajes aleatorios que se usarán en la evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2bc9e6af-fa6e-44d6-aa99-29e5f729f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_mensajes_y_claves(n_mensajes, bits):\n",
    "    mensajes = generar_mensajes(n_mensajes, bits).astype(np.float32)\n",
    "    claves = np.random.randint(0, 2, size=(mensajes.shape[0], bits)).astype(np.float32)\n",
    "\n",
    "    return mensajes, claves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308a7ce-25f9-40d9-a807-15a1e56c2553",
   "metadata": {},
   "source": [
    "**analizar_resultados**: Recoge una serie de métricas: la precisión media, la distancia de Hamming media y el número de reconstrucciones perfectas obtenido, tanto por Bob, como por Eve, como por el Bob que usa claves erróneas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20465898-875d-4d4a-8f1d-3f9ed429c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_resultados(mensajes, cifrados, reconstruidos_bob, reconstruidos_eve, muestras, res_file_name):\n",
    "\n",
    "    precisiones_bob = []\n",
    "    precisiones_eve = []\n",
    "    \n",
    "    dist_bob = []\n",
    "    dist_eve = []\n",
    "\n",
    "    reconstrucciones_perfectas_bob = 0\n",
    "    reconstrucciones_perfectas_eve = 0\n",
    "\n",
    "    for i in range(len(cifrados)):\n",
    "        original = mensajes[i].astype(int)\n",
    "\n",
    "        reconstruidos_b = (reconstruidos_bob[i] > 0.5).astype(int)\n",
    "        reconstruidos_e = (reconstruidos_eve[i] > 0.5).astype(int)\n",
    "\n",
    "        precicion_bob = np.mean(original == reconstruidos_b)\n",
    "        precicion_eve = np.mean(original == reconstruidos_e)\n",
    "\n",
    "        distancia_hamming_bob = np.sum(original != reconstruidos_b)\n",
    "        distancia_hamming_eve = np.sum(original != reconstruidos_e)\n",
    "\n",
    "        if i < muestras:\n",
    "            str_original = f\"[{i+1}] Original  --> {original}\\n\"\n",
    "            str_reconstruido_bob = f\"     Bob       --> {reconstruidos_b}   | Precisión: {precicion_bob:.2f} | Hamming: {distancia_hamming_bob}\\n\"\n",
    "            str_reconstruido_eve = f\"     Eve       --> {reconstruidos_e}   | Precisión: {precicion_eve:.2f} | Hamming: {distancia_hamming_eve}\\n\"\n",
    "            str_mensaje_delimiter = (\"-\" * 60) + \"\\n\"\n",
    "            str_muestra = str_original + str_reconstruido_bob + str_reconstruido_eve + str_mensaje_delimiter\n",
    "            with open(res_file_name, \"a\") as f:\n",
    "                f.write(str_muestra)\n",
    "\n",
    "        precisiones_bob.append(precicion_bob)\n",
    "        precisiones_eve.append(precicion_eve)\n",
    "        dist_bob.append(distancia_hamming_bob)\n",
    "        dist_eve.append(distancia_hamming_eve)\n",
    "\n",
    "        if distancia_hamming_bob == 0:\n",
    "            reconstrucciones_perfectas_bob += 1\n",
    "        \n",
    "        if distancia_hamming_eve == 0:\n",
    "            reconstrucciones_perfectas_eve += 1\n",
    "    \n",
    "    return precisiones_bob, precisiones_eve, dist_bob, dist_eve, reconstrucciones_perfectas_bob, reconstrucciones_perfectas_eve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe87737-b769-4bd6-b41c-e96d58f6eb9b",
   "metadata": {},
   "source": [
    "**analizar_resultados_errado**: Reune las mismas métricas pero para reconstrucciones que hace Bob con claves que no son los que se usaron para cifrar. Las claves se generan aleatoriamente, pero hay 2^32 opciones, por lo que la probabilidad de que las 10000 generadas coincidan es mínima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "582cfe32-62bc-43c5-a138-309a34208549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_resultados_errado(bob, bits, mensajes, cifrados, muestras, res_file_name):\n",
    "    precisiones_bob_errado = []\n",
    "    distancias_bob_errado = []\n",
    "    reconstrucciones_perfectas_errado = 0\n",
    "\n",
    "    claves_erradas = np.random.randint(0, 2, size=(mensajes.shape[0], bits)).astype(np.float32)\n",
    "    reconstruidos_bob_errado = bob.predict([cifrados, claves_erradas])\n",
    "\n",
    "    for i in range(len(cifrados)):\n",
    "        original = mensajes[i].astype(int)\n",
    "        reconstruidos_bob_err = (reconstruidos_bob_errado[i] > 0.5).astype(int)\n",
    "        \n",
    "        acc_err = np.mean(original == reconstruidos_bob_err)\n",
    "        hamming_err = np.sum(original != reconstruidos_bob_err)\n",
    "\n",
    "        if i < muestras:\n",
    "            str_bob_errado = f\"[{i+1}] Bob (clave errada) --> {reconstruidos_bob_err} | Precisión: {acc_err:.2f} | Hamming: {hamming_err}\\n\"\n",
    "            str_mensaje_delimiter_errado = (\"-\" * 60) + \"\\n\"\n",
    "            str_errado = str_bob_errado + str_mensaje_delimiter_errado\n",
    "            with open(res_file_name, \"a\") as f:\n",
    "                f.write(str_errado)\n",
    "\n",
    "        precisiones_bob_errado.append(acc_err)\n",
    "        distancias_bob_errado.append(hamming_err)\n",
    "\n",
    "        if(hamming_err == 0):\n",
    "            reconstrucciones_perfectas_errado += 1\n",
    "    \n",
    "    return precisiones_bob_errado, distancias_bob_errado, reconstrucciones_perfectas_errado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ea9ca-6a94-4660-a3aa-c131d425248c",
   "metadata": {},
   "source": [
    "**evaluar**: Usa los anteriores para llevar a cabo la evaluación. Este método devuelve las métricas que luego se enviarán al método que dibuja las gráficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "172bbffe-9151-44ac-807a-db8925f45735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar(n_mensajes, bits, muestras, epochs, res_file_name):\n",
    "\n",
    "    # Cargamos y creamos los modelos\n",
    "    alice, bob, eve = crear_y_cargar_modelos(bits)\n",
    "\n",
    "    mensajes, claves = generar_mensajes_y_claves(n_mensajes, bits)\n",
    "\n",
    "    # Tanto Bob como Eve intentan reconstruir\n",
    "    cifrados = alice.predict([mensajes, claves])\n",
    "    reconstruidos_bob = bob.predict([cifrados, claves])\n",
    "    reconstruidos_eve = eve.predict(cifrados)\n",
    "\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(f\"\\nEVALUACIÓN CON {epochs}:\\n\\n\")\n",
    "    \n",
    "    (\n",
    "        precisiones_bob, \n",
    "        precisiones_eve, \n",
    "        dist_bob, \n",
    "        dist_eve, \n",
    "        reconstrucciones_perfectas_bob, \n",
    "        reconstrucciones_perfectas_eve\n",
    "    ) = analizar_resultados(mensajes, cifrados, reconstruidos_bob, reconstruidos_eve, muestras, res_file_name)\n",
    "\n",
    "    media_precisiones_bob = np.mean(precisiones_bob)\n",
    "    media_precisiones_eve = np.mean(precisiones_eve)\n",
    "    media_distancias_bob = np.mean(dist_bob)\n",
    "    media_distancias_eve = np.mean(dist_eve)\n",
    "    str_titulo = \"\\nRESULTADOS FINALES\\n\\n\"\n",
    "    str_precision_bob = f\"Bob -> Precisión media: {media_precisiones_bob:.4f} | Hamming media: {media_distancias_bob:.2f}\\n\"\n",
    "    str_precision_eve = f\"Eve -> Precisión media: {media_precisiones_eve:.4f} | Hamming media: {media_distancias_eve:.2f}\\n\"\n",
    "    str_reconstrucciones_perfectas = f\"Bob -> Perfectas: {reconstrucciones_perfectas_bob} | Eve -> Perfectas: {reconstrucciones_perfectas_eve}\\n\"\n",
    "\n",
    "    str_resultados_finales = str_titulo + str_precision_bob + str_precision_eve + str_reconstrucciones_perfectas\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(str_resultados_finales)\n",
    "\n",
    "    # En este trozo se generan claves erradas y se intenta que Bob descifre con ellas\n",
    "    # Es lo mismo, pero con un set de claves nuevo\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(\"\\nEVALUACIÓN CON CLAVES ERRÓNEAS PARA BOB\\n\\n\")\n",
    "\n",
    "    (\n",
    "        precisiones_bob_errado, \n",
    "        distancias_bob_errado, \n",
    "        reconstrucciones_perfectas_errado\n",
    "    ) = analizar_resultados_errado(bob, bits, mensajes, cifrados, muestras, res_file_name)\n",
    "\n",
    "    media_precisiones_bob_errado = np.mean(precisiones_bob_errado)\n",
    "    media_distancias_bob_errado = np.mean(distancias_bob_errado)\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(\"\\nRESULTADOS CON CLAVES ERRÓNEAS\\n\\n\")\n",
    "        f.write(f\"Bob -> Precisión media (clave errada): {media_precisiones_bob_errado:.4f} | Hamming media: {media_distancias_bob_errado:.2f}\\n\")\n",
    "\n",
    "    return [media_precisiones_bob, media_precisiones_eve, media_distancias_bob, media_distancias_eve, reconstrucciones_perfectas_bob, reconstrucciones_perfectas_eve, media_precisiones_bob_errado, media_distancias_bob_errado, reconstrucciones_perfectas_errado]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbddeef-8a06-4caa-a955-50913cd0b615",
   "metadata": {},
   "source": [
    "## Representando los resultados\n",
    "\n",
    "Tan importante como desarrollar un buen código, es poder enseñar los resultados de manera ilustrativa. Para ello, en esta sección se define la creación de una gráfica para poder visualizar los resultados obtenidos en la ejecución. Las métricas se recogen en el main y se guardan en un diccionario. Así mismo, también recibe el nombre de la figura, al que simplemente se le añade el formato al guardarla y el número de mensajes, que es útil para establecer un límite en la gráfica que muestra las reconstrucciones perfectas realizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aed89109-0af1-41de-9dc2-77367adb8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(diccionario_medidas, n_mensajes, nombre_figura):\n",
    "\n",
    "    list_epochs = diccionario_medidas[\"epochs\"]\n",
    "    list_training_times = diccionario_medidas[\"training_times\"]\n",
    "\n",
    "    list_precisiones_bob = diccionario_medidas[\"precisiones_bob\"]\n",
    "    list_precisiones_eve = diccionario_medidas[\"precisiones_eve\"]\n",
    "    list_precisiones_bob_errado = diccionario_medidas[\"precisiones_bob_errado\"]\n",
    "    \n",
    "    list_distancias_hamming_bob = diccionario_medidas[\"distancias_hamming_bob\"]\n",
    "    list_distancias_hamming_eve = diccionario_medidas[\"distancias_hamming_eve\"]\n",
    "    list_distancias_hamming_bob_errado = diccionario_medidas[\"distancias_bob_errado\"]\n",
    "\n",
    "    list_reconstrucciones_perfectas_bob = diccionario_medidas[\"reconstrucciones_perfectas_bob\"]\n",
    "    list_reconstrucciones_perfectas_eve = diccionario_medidas[\"reconstrucciones_perfectas_eve\"]\n",
    "    list_reconstrucciones_perfectas_errado = diccionario_medidas[\"reconstrucciones_perfectas_errado\"]\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(list_epochs, list_training_times, c=\"red\", marker='o', markersize=3, markerfacecolor=\"red\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Duración del entrenamiento (s)\")\n",
    "    plt.title(\"Epochs - Entrenamiento\")\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(bottom = 0)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(list_epochs, list_precisiones_bob, c=\"red\", label = \"Prec Bob\", marker='o', markersize=3, markerfacecolor=\"red\")\n",
    "    plt.plot(list_epochs, list_precisiones_bob_errado, c=\"blue\", label = \"Prec errada\", linestyle=\"dashed\", marker='o', markersize=3, markerfacecolor=\"blue\")\n",
    "    plt.plot(list_epochs, list_precisiones_eve, c=\"black\", label = \"Prec Eve\", marker='o', linestyle=\"dotted\", markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Media precisión descifrado\")\n",
    "    plt.title(\"Epochs - Precisión media\")\n",
    "    plt.legend()\n",
    "    plt.xlim(left = 0)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(list_epochs, list_distancias_hamming_bob, c=\"red\", label = \"Dists. Bob\", marker='o', markersize=3, markerfacecolor=\"red\")\n",
    "    plt.plot(list_epochs, list_distancias_hamming_bob_errado, c=\"blue\", label = \"Dists. erradas\", linestyle=\"dashed\", marker='o', markersize=3, markerfacecolor=\"blue\")\n",
    "    plt.plot(list_epochs, list_distancias_hamming_eve, c=\"black\", label = \"Dists. Eve\", marker='o', linestyle=\"dotted\", markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Media distancias de Hamming\")\n",
    "    plt.title(\"Epochs - Distancias de Hamming\")\n",
    "    plt.legend()\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(bottom = 0)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(list_epochs, list_reconstrucciones_perfectas_bob, c=\"red\", label = \"Perfectas Bob\", marker='o', markersize=3, markerfacecolor=\"red\")\n",
    "    plt.plot(list_epochs, list_reconstrucciones_perfectas_errado, c=\"blue\", label = \"Pefectas errado\", linestyle=\"dashed\", marker='o', markersize=3, markerfacecolor=\"blue\")\n",
    "    plt.plot(list_epochs, list_reconstrucciones_perfectas_eve, c=\"black\", label = \"Perfectas Eve\", linestyle=\"dotted\", marker='o', markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Reconstrucciones perfectas\")\n",
    "    plt.title(\"Epochs - Reconstrucciones perfectas\")\n",
    "    plt.legend()\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(0, n_mensajes)\n",
    "\n",
    "    plt.subplots_adjust(left = 0.125, bottom = 0.11, right = 1.1, top = 0.9, wspace = 0.44, hspace = 0.45)\n",
    "    plt.savefig(nombre_figura + \".png\", bbox_inches='tight', dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29bfaf-89b5-4395-8c7c-0c086f3bf564",
   "metadata": {},
   "source": [
    "## Código principal\n",
    "\n",
    "Aquí se define el código principal. Este es un main que tiene un bucle que ejecuta el código una vez. Con ayuda de bucles se puede conseguir que se ejecute más veces, pero en pos de visualizar la gráfica resultante, se ha dejado una sola ejecución.\n",
    "\n",
    "Aquí es donde se definen los hiperparámetros que se utilizarán, como el tamaño del _batch_.\n",
    "\n",
    "La ejecución tarda en completarse, mucho más que en los escenarios 1. Se han dejado los mensajes que Tensorflow y Keras imprimen por pantalla y se ha añadido uno, que sale en cada ronda de entrenamiento y da información acerca de por dónde y cómo va.\n",
    "\n",
    "Además, aquí se recogen las métricas que se usan para dibujar las gráficas, los métodos de entrenamiento y evaluación devuelven el tiempo que duró el entrenamiento y las métricas recogidas durante la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0084c-ec00-4f58-bc40-7dca29ecf66f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    nombre_figura = \"21 - 512 y 0,001 cada 500\"\n",
    "\n",
    "    res_file_name = f\"Resultados de {nombre_figura}.txt\"\n",
    "    with open(res_file_name, \"w\") as f:\n",
    "        f.write(\"-- RESULTADOS DEL EXPERIMENTO 2.1. --\\n\\n\")\n",
    "\n",
    "    n_mensajes = 10000\n",
    "    bits = 32\n",
    "    epochs = 500\n",
    "    step = 500\n",
    "    total_epochs = 6000\n",
    "    batch_size = 512\n",
    "    adam_optimizer = 0.001\n",
    "    alfa = 0.1\n",
    "    beta = 0.2\n",
    "    gamma = 0.7\n",
    "    muestras = 10\n",
    "\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(f\"Número de mensajes = {n_mensajes}\\n\")\n",
    "        f.write(f\"Número de bits = {bits}\\n\")\n",
    "        f.write(f\"Tamaño del batch = {batch_size}\\n\")\n",
    "        f.write(f\"Adam optimizer learning rate = {adam_optimizer}\\n\")\n",
    "        f.write(f\"Epochs totales = {total_epochs}\\n\")\n",
    "        f.write(f\"Epochs iniciales = {epochs}\\n\")\n",
    "        f.write(f\"alfa = {alfa}\\n\")\n",
    "        f.write(f\"beta = {beta}\\n\")\n",
    "        f.write(f\"gamma = {gamma}\\n\")\n",
    "\n",
    "    diccionario_medidas = {\n",
    "        \"epochs\": [],\n",
    "        \"training_times\": [],\n",
    "        \"precisiones_bob\": [],\n",
    "        \"precisiones_eve\": [],\n",
    "        \"distancias_hamming_bob\": [],\n",
    "        \"distancias_hamming_eve\": [],\n",
    "        \"reconstrucciones_perfectas_bob\": [],\n",
    "        \"reconstrucciones_perfectas_eve\": [],\n",
    "        \"precisiones_bob_errado\": [],\n",
    "        \"distancias_bob_errado\": [],\n",
    "        \"reconstrucciones_perfectas_errado\": []\n",
    "    }\n",
    "    \n",
    "    \n",
    "    time_0 = t.time()\n",
    "    while epochs <= total_epochs:\n",
    "        training_time = entrenar(n_mensajes, bits, epochs, batch_size, adam_optimizer, alfa, beta, gamma)\n",
    "        \n",
    "        res_list = evaluar(n_mensajes, bits, muestras, epochs, res_file_name)\n",
    "\n",
    "        precisiones_bob = res_list[0]\n",
    "        precisiones_eve = res_list[1]\n",
    "        distancias_hamming_bob = res_list[2]\n",
    "        distancias_hamming_eve = res_list[3]\n",
    "        reconstrucciones_perfectas_bob = res_list[4]\n",
    "        reconstrucciones_perfectas_eve = res_list[5]\n",
    "        precisiones_bob_errado = res_list[6]\n",
    "        distancias_bob_errado = res_list[7]\n",
    "        reconstrucciones_perfectas_errado = res_list[8]\n",
    "\n",
    "        diccionario_medidas[\"epochs\"].append(epochs)\n",
    "        diccionario_medidas[\"training_times\"].append(training_time)\n",
    "        \n",
    "        diccionario_medidas[\"precisiones_bob\"].append(precisiones_bob)\n",
    "        diccionario_medidas[\"distancias_hamming_bob\"].append(distancias_hamming_bob)\n",
    "        diccionario_medidas[\"reconstrucciones_perfectas_bob\"].append(reconstrucciones_perfectas_bob)\n",
    "        \n",
    "        diccionario_medidas[\"precisiones_eve\"].append(precisiones_eve)\n",
    "        diccionario_medidas[\"distancias_hamming_eve\"].append(distancias_hamming_eve)\n",
    "        diccionario_medidas[\"reconstrucciones_perfectas_eve\"].append(reconstrucciones_perfectas_eve)\n",
    "\n",
    "        diccionario_medidas[\"precisiones_bob_errado\"].append(precisiones_bob_errado)\n",
    "        diccionario_medidas[\"distancias_bob_errado\"].append(distancias_bob_errado)\n",
    "        diccionario_medidas[\"reconstrucciones_perfectas_errado\"].append(reconstrucciones_perfectas_errado)\n",
    "\n",
    "        epochs += step\n",
    "    \n",
    "    total_time = t.time() - time_0\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(f\"\\nTiempo total de ejecución (s): {total_time}\\n\")\n",
    "        f.write(f\"Tiempo total de ejecución (mins): {total_time/60}\")\n",
    "\n",
    "    draw_graph(diccionario_medidas, n_mensajes, nombre_figura)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e439987-0c47-4eb4-98d2-f3dc5ab22aee",
   "metadata": {},
   "source": [
    "El resultado de la ejecución aparecerá encima de este texto y producirá una imagen al finalizar la ejecución con todos los resultados. Además, la imagen generada con las gráficas también queda guardada en el directorio de esta Jupyter Notebook.\n",
    "\n",
    "Se anima a jugar con los parámetros, como el tamaño del _batch_, las _epochs_, el _adam optimizer_... para probar el rendimiento en distintos casos. Además, en este escenario se han añadido los hiperparámetros alfa, beta y gamma, que permiten ajustar el funcionamiento de las redes neuronales influyendo en la función de coste/pérdida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
