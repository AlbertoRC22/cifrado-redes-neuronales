{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49df5521-211f-4497-b4ca-6c4a1af675bf",
   "metadata": {},
   "source": [
    "# Escenario 1.3. - Alice y Bob con clave, pero separados\n",
    "\n",
    "En este escenario se cubre el caso en el que Alice cifra para Bob y Bob intenta descifrar los mensajes por medio de una clave.\n",
    "\n",
    "Se lleva a cabo un entrenamiento, una evaluación de los resultados y se dibuja una gráfica para ilustrarlos. Como se hacen muchas ejecuciones, se grafica el resultado obtenido en cada ejecución. Hay cierta variabilidad en los resultados al ser los pesos de las redes neuronales aleatorios, así como los mensajes generados en el entrenamiento y la evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58d4c1-ca19-4ad2-bcb5-8352d8fb8adb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd50d46-9f7f-451a-a337-e53840632f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from data_utils import generar_mensajes\n",
    "\n",
    "import numpy as np\n",
    "import time as t\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059af08-3b25-43f0-9d51-87f5cdff2adc",
   "metadata": {},
   "source": [
    "## Las redes neuronales\n",
    "\n",
    "En esta sección definimos las redes a utilizar más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d7eca2-2f52-4ed0-8293-cc30a8b8295b",
   "metadata": {},
   "source": [
    "**Alice**: Red neuronal que cifra los mensajes.\n",
    "1. Recibe como parámetro el número de bits de los mensajes que va a cifrar y entonces define la forma de entrada.\n",
    "2. Concatena el mensaje de entrada con al clave y eso es lo que se le pasa a la red.\n",
    "3. Va a tener dos capas, con 128 y 64 neuronas, que reciben la entrada de la anterior y usan la función de activación relu. _Dense_ quiere decir que la capa está completamente conectada con la anterior.\n",
    "\n",
    "La última capa tiene una función de activación lineal porque luego la va a procesar Bob. No es necesario que sea binaria todavía. Tiene también tantas neuronas como bits, porque se busca que saque el mensaje cifrado y, por último, la función kernel_regularizer ayuda a evitar el sobreajuste penalizando las capas, de forma a que afecta la función de pérdida/coste.\n",
    "\n",
    "En el return, devolvemos un modelo que recibe de entrada el mensaje junto con la clave, que en los escenarios anteriores se había llamado \"final_input\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19daad7-435e-49e4-ae3b-4a70546eda4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo_alice(bits, key=True):\n",
    "    \n",
    "    input_msg = Input(shape=(bits,), name='mensaje_original')\n",
    "    input_key = Input(shape=(bits,), name='clave_simetrica')\n",
    "    \n",
    "    x = Concatenate()([input_msg, input_key])\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "\n",
    "    cifrado = Dense(bits, activation='linear', kernel_regularizer=l2(0.01))(x)\n",
    "\n",
    "    return Model([input_msg, input_key], cifrado, name='Alice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c95fb62-cf1d-41d8-9bc7-8eb5116fe3e2",
   "metadata": {},
   "source": [
    "**Bob**: Red neuronal que descifra los mensajes.\n",
    "Funciona parecido a Alice, salvo que tiene capas de 64 y 64 neuronas. \n",
    "Lo más destacable es que la función de activación de la última capa es, en este caso, la función sigmoide. La función sigmoide devuelve un valor entre 0 y 1 y esos son los valores que luego se procesan para inferir si la predicción es el valor 0 o el valor 1 en la reconstrucción.\n",
    "\n",
    "Además, en este escenario cabe destacar que el mensaje cifrado de entrada y la clave recibida se concatenan.\n",
    "\n",
    "En el return, devolvemos un modelo que recibe de entrada el mensaje junto con la clave, que en los escenarios anteriores se había llamado \"final_input\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77524ef2-d182-4e0a-8495-542298be5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo_bob(bits, key=True):\n",
    "    input_cifrado = Input(shape=(bits,), name='mensaje_cifrado')\n",
    "    input_key = Input(shape=(bits,), name='clave_simetrica')\n",
    "\n",
    "    x = Concatenate()([input_cifrado, input_key])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "\n",
    "    reconstruido = Dense(bits, activation='sigmoid')(x)\n",
    "\n",
    "    return Model([input_cifrado, input_key], reconstruido, name='Bob')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67faab8e-7de5-4091-9655-b018fb3206ac",
   "metadata": {},
   "source": [
    "## Código de entrenamiento\n",
    "\n",
    "Esta sección se encarga de entrenar los modelos de Alice y Bob. Tiene dos métodos:\n",
    "\n",
    "* generar_mensajes_y_clave, que sirve para generar los mensajes aleatorios y la clave única. Al entrenar de manera separada, es más difícil que logrren su objetivo y, para ejemplificarlo mejor, se ha dejado uan sola clave para todo el entrenamiento.\n",
    "* entrenar, que en este escenario es más grande que en el 1.1. y 1.2. Se generan la clave y los mensajes, para después instanciar las redes de Alice y Bob y entrenarla spor separado. Primero, Alice aprenderá a cifrar mensajes sin Bob, utilziando una única clave para todos los mensajes, al contrario que en los escenarios 1.1. y 1.2. Después, Bob entrenará con los mensajes cifrados por Alice, como en los casos anteriores, pero por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eba2690-8278-451f-a4df-3f2ede8b386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_mensajes_y_clave(n_mensajes, bits): \n",
    "    # Para simplificar por tener entrenamiento separado, se genera una sola clave\n",
    "    clave_fija = np.random.randint(0, 2, size=(1, bits)).astype(np.float32)\n",
    "    \n",
    "    # Generamos los mensajes\n",
    "    mensajes = generar_mensajes(n_mensajes, bits)\n",
    "    \n",
    "    return clave_fija, mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe74940-4379-489f-8d22-1b7ee3dceee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(n_mensajes, bits, epochs, batch_size, adam_optimizer):\n",
    "    # Generamos una única clave y los mensajes\n",
    "    clave_fija, mensajes = generar_mensajes_y_clave(n_mensajes, bits)\n",
    "\n",
    "    # Entrenamiento de Alice\n",
    "    alice = crear_modelo_alice(bits, key=True)\n",
    "    alice.compile(optimizer=Adam(adam_optimizer), loss=BinaryCrossentropy())\n",
    "\n",
    "    time_0 = t.time()\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "        \n",
    "        idx = np.random.choice(n_mensajes, batch_size)\n",
    "        mensajes_batch = mensajes[idx]\n",
    "        claves_batch = np.repeat(clave_fija, batch_size, axis=0)\n",
    "\n",
    "        cifrados_batch = alice.predict([mensajes_batch, claves_batch])  # inicialización\n",
    "        alice.train_on_batch([mensajes_batch, claves_batch], cifrados_batch)\n",
    "\n",
    "        print(f\"Época {epoch+1} de {epochs} Alice\")\n",
    "\n",
    "    # Guardamos el modelo de Alice, ya entrenado\n",
    "    alice.save(\"modelo_alice_separado.keras\")\n",
    "\n",
    "    # Ahora generamos los cifrados que Bob tendrá que aprender a descifrar\n",
    "    claves_completas = np.repeat(clave_fija, n_mensajes, axis=0)\n",
    "    cifrados = alice.predict([mensajes, claves_completas])\n",
    "\n",
    "    # Instanciamos y entrenamos a Bob\n",
    "    bob = crear_modelo_bob(bits, key=True)\n",
    "    bob.compile(optimizer=Adam(adam_optimizer), loss=BinaryCrossentropy())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "        \n",
    "        idx = np.random.choice(n_mensajes, batch_size)\n",
    "        cifrados_batch = cifrados[idx]\n",
    "        mensajes_batch = mensajes[idx]\n",
    "\n",
    "        # Repite la clave para usar la misma en todo el batch\n",
    "        claves_batch = np.repeat(clave_fija, batch_size, axis=0)\n",
    "\n",
    "        bob.train_on_batch([cifrados_batch, claves_batch], mensajes_batch)\n",
    "        reconstruidos = bob.predict([cifrados_batch, claves_batch])\n",
    "\n",
    "        acc = np.mean((reconstruidos > 0.5).astype(int) == mensajes_batch)\n",
    "        print(f\"Época {epoch+1} de {epochs} Bob - Precisión del descifrado: {acc:.3f}\")\n",
    "\n",
    "    print(\"Guardando modelo de Bob\")\n",
    "    bob.save(\"modelo_bob_separado.keras\")\n",
    "\n",
    "    time = t.time() - time_0\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d47b8-bcd0-408b-aacc-d629d8e8bd81",
   "metadata": {},
   "source": [
    "## Código de evaluación\n",
    "\n",
    "Esta sección se encarga de evaluar el entrenamiento y consiste también en tres métodos:\n",
    "* El método cargar_modelos, que crea a Alice y a Bob y les carga los pesos finales obtenidos en el entrenamiento.\n",
    "* El método generar_cifrados, que genera los mensajes cifrados que Bob intenta reconstruir.\n",
    "* El método analizar_resultados, que recoge una serie de métricas: la precisión media, la distancia de Hamming media y el número de reconstrucciones perfectas obtenido.\n",
    "* El método evaluar, que usa los anteriores para llevar a cabo la evaluación. Este método devuelve las métricas que luego se enviarán al método que dibuja las gráficas.\n",
    "\n",
    "Nótese que también se incluye el escribir en un fichero de texto los resultados. Así se pueden consultar los resultados exactos más fácilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f3c623-3664-4fcb-bbbc-71ed0b5b96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelos(bits):\n",
    "    alice = crear_modelo_alice(bits)\n",
    "    bob = crear_modelo_bob(bits)\n",
    "\n",
    "    alice.load_weights('modelo_alice_separado.keras')\n",
    "    bob.load_weights('modelo_bob_separado.keras')\n",
    "\n",
    "    return alice, bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef19ef9-a0d1-4aba-9678-67dbbdf73338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_cifrados(bits, alice, bob, mensajes):\n",
    "    clave_fija = np.random.randint(0, 2, size=(1, bits)).astype(np.float32)\n",
    "    claves = np.repeat(clave_fija, mensajes.shape[0], axis=0)\n",
    "\n",
    "    cifrados = alice.predict([mensajes, claves])\n",
    "    reconstruidos = bob.predict([cifrados, claves])\n",
    "\n",
    "    return reconstruidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca0067db-c80a-494f-8740-2585ca639fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_resultados(muestras, res_file_name, mensajes, reconstruidos):\n",
    "\n",
    "    precisiones = []\n",
    "    distancias = []\n",
    "    reconstrucciones_perfectas = 0\n",
    "\n",
    "    for i in range(len(reconstruidos)):\n",
    "        original = mensajes[i].astype(int)\n",
    "        reconstruido = (reconstruidos[i] > 0.5).astype(int)\n",
    "\n",
    "        # Coges el original y el reconstruido y haces la media de cuántos bits se parecen\n",
    "        precision = np.mean(original == reconstruido)\n",
    "        distancia_hamming = np.sum(original != reconstruido)\n",
    "\n",
    "        if i < muestras:\n",
    "            str_mensaje_original = f\"Original     --> {original}\\n\"\n",
    "            str_precision_reconstruido = f\"Reconstruido --> {reconstruido} | Precisión: {precision:.2f}\\n\"\n",
    "            str_distancia_hamming = f\"Distancia de Hamming: {distancia_hamming}\\n\"\n",
    "            str_mensaje_delimiter = (\"-\" * 50) + \"\\n\"\n",
    "            str_muestra = str_mensaje_original + str_precision_reconstruido + str_distancia_hamming + str_mensaje_delimiter\n",
    "            with open(res_file_name, \"a\") as f:\n",
    "                f.write(str_muestra)\n",
    "\n",
    "        precisiones.append(precision)\n",
    "        distancias.append(distancia_hamming)\n",
    "        if distancia_hamming == 0:\n",
    "            reconstrucciones_perfectas += 1\n",
    "\n",
    "    return precisiones, distancias, reconstrucciones_perfectas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51b4044-c417-4c4e-9549-0c59c4c7f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar(bits, muestras, res_file_name, epochs):\n",
    "    # Cargamos los modelos y los pesos del entrenamiento anterior\n",
    "    alice, bob = cargar_modelos(bits)\n",
    "\n",
    "    print(\"GENERANDO MENSAJES\")\n",
    "    mensajes = generar_mensajes(n=muestras, bits=bits)\n",
    "\n",
    "    reconstruidos = generar_cifrados(bits, alice, bob, mensajes)\n",
    "\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(f\"\\nEVALUACIÓN CON {epochs}:\\n\\n\")\n",
    "\n",
    "    precisiones, distancias, reconstrucciones_perfectas = analizar_resultados(muestras, res_file_name, mensajes, reconstruidos)\n",
    "\n",
    "    media_precision = np.mean(precisiones)\n",
    "    media_distancias = np.mean(distancias)\n",
    "\n",
    "    str_media_precision = f\"La media de la precisión del descifrado es {media_precision:.4f}\\n\"\n",
    "    str_media_distancias = f\"Distancia media de Hamming = {media_distancias:.4f} | Número de bits: {bits}\\n\"\n",
    "    str_reconstrucciones_perfectas = f\"Número de reconstrucciones perfectas = {reconstrucciones_perfectas}\\n\"\n",
    "    str_medidas = str_media_precision + str_media_distancias + str_reconstrucciones_perfectas + \"\\n\\n\"\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(str_medidas)\n",
    "    \n",
    "    return [media_precision, media_distancias, reconstrucciones_perfectas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62dbdc2-3308-465a-9fa3-86c600a8b962",
   "metadata": {},
   "source": [
    "## Representando los resultados\n",
    "\n",
    "Tan importante como desarrollar un buen código, es poder enseñar los resultados de manera ilustrativa. Para ello, en esta sección se define la creación de una gráfica para poder visualizar los resultados obtenidos en la ejecución. Las métricas se recogen en el main y se guardan en un diccionario. Así mismo, también recibe el nombre de la figura, al que simplemente se le añade el formato al guardarla y el número de mensajes, que es útil para establecer un límite en la gráfica que muestra las reconstrucciones perfectas realizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b7cfccd-2f7b-4efa-933f-d2d941a75e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(diccionario_medidas, n_mensajes, nombre_figura):\n",
    "\n",
    "    list_epochs = diccionario_medidas[\"epochs\"]\n",
    "    list_training_times = diccionario_medidas[\"training_times\"]\n",
    "    list_media_precision = diccionario_medidas[\"media_precision\"]\n",
    "    list_media_distancias = diccionario_medidas[\"media_distancias\"]\n",
    "    list_reconstrucciones_perfectas = diccionario_medidas[\"reconstrucciones_perfectas\"]\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(list_epochs, list_training_times, c=\"red\", marker='o', markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Duración entrenamiento (s)\")\n",
    "    plt.title(\"Entrenamiento - Epochs\")\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(bottom = 0)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(list_epochs, list_media_precision, c=\"red\", marker='o', markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Media precisión descifrado\")\n",
    "    plt.title(\"Precisión media - Epochs\")\n",
    "    plt.xlim(left = 0)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(list_epochs, list_media_distancias, c=\"red\", marker='o', markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Media distancias de Hamming\")\n",
    "    plt.title(\"Distancias de Hamming - Epochs\")\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(bottom = 0)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(list_epochs, list_reconstrucciones_perfectas, c=\"red\", marker='o', markersize=3, markerfacecolor=\"black\")\n",
    "    plt.xlabel(\"Número de epochs\")\n",
    "    plt.ylabel(\"Reconstrucciones perfectas\")\n",
    "    plt.title(\"Reconstrucciones perfectas - Epochs\")\n",
    "    plt.xlim(left = 0)\n",
    "    plt.ylim(0, n_mensajes)\n",
    "\n",
    "    plt.subplots_adjust(left = 0.125, bottom = 0.11, right = 1.1, top = 0.9, wspace = 0.44, hspace = 0.45)\n",
    "    plt.savefig(nombre_figura + \".png\", bbox_inches='tight', dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a1b89-0a88-43cf-bcc8-3be81bbd9a2e",
   "metadata": {},
   "source": [
    "## Código principal\n",
    "\n",
    "Aquí se define el código principal. Este es un main que tiene un bucle que ejecuta el código una vez. Con ayuda de bucles se puede conseguir que se ejecute más veces, y es lo que se hizo para obtener los resultados más cómodamente, pero en este caso, en pro de visualizar la gráfica resultante, se ha dejado una sola  ejecución.\n",
    "\n",
    "Aquí es donde se definen los hiperparámetros que se utilizarán, como el tamaño del _batch_.\n",
    "\n",
    "La ejecución tarda en completarse. Por ello, se han dejado los mensajes que Tensorflow y Keras imprimen por pantalla y se ha añadido uno, que sale en cada ronda de entrenamiento y da información acerca de por dónde y cómo va. Hay mucha salida, pero el tamaño queda limitado.\n",
    "\n",
    "Además, aquí se recogen las métricas que se usan para dibujar las gráficas, los métodos de entrenamiento y evaluación devuelven el tiempo que duró el entrenamiento y las métricas recogidas durante la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab2e5169-d572-4255-9f6d-6339f3330133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 301 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 302 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 303 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 304 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 305 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 306 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Época 307 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 308 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 309 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Época 310 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 311 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Época 312 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 313 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 314 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 315 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 316 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 317 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 318 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 319 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 320 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 321 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 322 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 323 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 324 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 325 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 326 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 327 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 328 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 329 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 330 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 331 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 332 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 333 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 334 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 335 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Época 336 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 337 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Época 338 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 339 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 340 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 341 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 342 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 343 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 344 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 345 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 346 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 347 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Época 348 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 349 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 350 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 351 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 352 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 353 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 354 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 355 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 356 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 357 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 358 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 359 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 360 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 361 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 362 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 363 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 364 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 365 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Época 366 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 367 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 368 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 369 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 370 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 371 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 372 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 373 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 374 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 375 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 376 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 377 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 378 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 379 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 380 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 381 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 382 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Época 383 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 384 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 385 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 386 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Época 387 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 388 de 500 Alice\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Época 389 de 500 Alice\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     f.write(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m epochs <= total_epochs:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     training_time = \u001b[43mentrenar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_mensajes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madam_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     res_list = evaluar(bits, muestras, res_file_name, epochs)\n\u001b[32m     39\u001b[39m     media_precision = res_list[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mentrenar\u001b[39m\u001b[34m(n_mensajes, bits, epochs, batch_size, adam_optimizer)\u001b[39m\n\u001b[32m     16\u001b[39m mensajes_batch = mensajes[idx]\n\u001b[32m     17\u001b[39m claves_batch = np.repeat(clave_fija, batch_size, axis=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m cifrados_batch = \u001b[43malice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmensajes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclaves_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# inicialización\u001b[39;00m\n\u001b[32m     20\u001b[39m alice.train_on_batch([mensajes_batch, claves_batch], cifrados_batch)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mÉpoca \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m de \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Alice\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\prueba\\.env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\prueba\\.env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:505\u001b[39m, in \u001b[36mTensorFlowTrainer.predict\u001b[39m\u001b[34m(self, x, batch_size, verbose, steps, callbacks)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@traceback_utils\u001b[39m.filter_traceback\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    502\u001b[39m     \u001b[38;5;28mself\u001b[39m, x, batch_size=\u001b[38;5;28;01mNone\u001b[39;00m, verbose=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, steps=\u001b[38;5;28;01mNone\u001b[39;00m, callbacks=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    503\u001b[39m ):\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# Create an iterator that yields batches of input data.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     epoch_iterator = \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    514\u001b[39m     \u001b[38;5;66;03m# Container that configures and calls callbacks.\u001b[39;00m\n\u001b[32m    515\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module.CallbackList):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\prueba\\.env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:726\u001b[39m, in \u001b[36mTFEpochIterator.__init__\u001b[39m\u001b[34m(self, distribute_strategy, *args, **kwargs)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(*args, **kwargs)\n\u001b[32m    725\u001b[39m \u001b[38;5;28mself\u001b[39m._distribute_strategy = distribute_strategy\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_adapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf.distribute.DistributedDataset):\n\u001b[32m    728\u001b[39m     dataset = \u001b[38;5;28mself\u001b[39m._distribute_strategy.experimental_distribute_dataset(\n\u001b[32m    729\u001b[39m         dataset\n\u001b[32m    730\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\prueba\\.env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:241\u001b[39m, in \u001b[36mArrayDataAdapter.get_tf_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    237\u001b[39m options = tf.data.Options()\n\u001b[32m    238\u001b[39m options.experimental_distribute.auto_shard_policy = (\n\u001b[32m    239\u001b[39m     tf.data.experimental.AutoShardPolicy.DATA\n\u001b[32m    240\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m dataset = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dataset.prefetch(tf.data.AUTOTUNE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\prueba\\.env\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3012\u001b[39m, in \u001b[36mDatasetV2.with_options\u001b[39m\u001b[34m(self, options, name)\u001b[39m\n\u001b[32m   2986\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_options\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, name=\u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[33m\"\u001b[39m\u001b[33mDatasetV2\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2987\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns a new `tf.data.Dataset` with the given options set.\u001b[39;00m\n\u001b[32m   2988\u001b[39m \n\u001b[32m   2989\u001b[39m \u001b[33;03m  The options are \"global\" in the sense they apply to the entire dataset.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3010\u001b[39m \u001b[33;03m    ValueError: when an option is set more than once to a non-default value\u001b[39;00m\n\u001b[32m   3011\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3012\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_OptionsDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\prueba\\.env\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4907\u001b[39m, in \u001b[36m_OptionsDataset.__init__\u001b[39m\u001b[34m(self, input_dataset, options, name)\u001b[39m\n\u001b[32m   4905\u001b[39m \u001b[38;5;28mself\u001b[39m._name = name\n\u001b[32m   4906\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(input_dataset._variant_tensor):\n\u001b[32m-> \u001b[39m\u001b[32m4907\u001b[39m   variant_tensor = \u001b[43mgen_dataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptions_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_pb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m      \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_common_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[38;5;28msuper\u001b[39m(_OptionsDataset, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m(input_dataset, variant_tensor)\n\u001b[32m   4912\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options_attr:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\prueba\\.env\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:4663\u001b[39m, in \u001b[36moptions_dataset\u001b[39m\u001b[34m(input_dataset, serialized_options, output_types, output_shapes, metadata, name)\u001b[39m\n\u001b[32m   4661\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   4662\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4663\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4664\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptionsDataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mserialized_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4665\u001b[39m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_types\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_shapes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4666\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4667\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   4668\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    nombre_figura = \"Figura 13 - Entrenamiento separado\"\n",
    "    res_file_name = \"Resultados_13.txt\"\n",
    "    with open(res_file_name, \"w\") as f:\n",
    "        f.write(\"-- RESULTADOS DEL EXPERIMENTO 1.3. --\\n\\n\")\n",
    "\n",
    "    n_mensajes = 10000\n",
    "    bits = 32\n",
    "    batch_size = 64\n",
    "    adam_optimizer = 0.001\n",
    "    muestras = 10\n",
    "\n",
    "    epochs = 500\n",
    "    step = 500\n",
    "    total_epochs = 4000\n",
    "\n",
    "    diccionario_medidas = {\n",
    "        \"epochs\": [],\n",
    "        \"training_times\": [],\n",
    "        \"media_precision\": [],\n",
    "        \"media_distancias\": [],\n",
    "        \"reconstrucciones_perfectas\": []\n",
    "    }\n",
    "\n",
    "    with open(res_file_name, \"a\") as f:\n",
    "        f.write(f\"Número de mensajes = {n_mensajes}\\n\")\n",
    "        f.write(f\"Número de bits = {bits}\\n\")\n",
    "        f.write(f\"Tamaño del batch = {batch_size}\\n\")\n",
    "        f.write(f\"Adam optimizer learning rate = {adam_optimizer}\\n\")\n",
    "        f.write(f\"Epochs totales = {total_epochs}\\n\")\n",
    "        f.write(f\"Epochs iniciales = {epochs}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    while epochs <= total_epochs:\n",
    "        training_time = entrenar(n_mensajes, bits, epochs, batch_size, adam_optimizer)\n",
    "        res_list = evaluar(bits, muestras, res_file_name, epochs)\n",
    "        \n",
    "        media_precision = res_list[0]\n",
    "        media_distancias = res_list[1]\n",
    "        reconstrucciones_perfectas = res_list[2]\n",
    "\n",
    "        diccionario_medidas[\"epochs\"].append(epochs)\n",
    "        diccionario_medidas[\"training_times\"].append(training_time)\n",
    "        diccionario_medidas[\"media_precision\"].append(media_precision)\n",
    "        diccionario_medidas[\"media_distancias\"].append(media_distancias)\n",
    "        diccionario_medidas[\"reconstrucciones_perfectas\"].append(reconstrucciones_perfectas)\n",
    "\n",
    "        epochs += step\n",
    "\n",
    "    draw_graph(diccionario_medidas, n_mensajes, nombre_figura)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b7d98-76e3-442a-b8a1-10d070c20689",
   "metadata": {},
   "source": [
    "El resultado de la ejecución aparecerá encima de este texto y producirá una imagen al finalizar la ejecución con todos los resultados. Además, la imagen generada con las gráficas también queda guardada en el directorio de esta Jupyter Notebook.\n",
    "\n",
    "En este escenario, los hiperparámetros no importan demasiado porque, al entrenar de manera separada, Alice y Bob no consiguen aprender a cifrar y descifdrar para el otro y por ello la precisión va a ser muy baja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c028fc-5500-4d8c-af1a-fadecf500b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35575010-2473-46de-8d3a-ef98e125c69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0688c-6517-4267-8d7d-3aab657e5834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
